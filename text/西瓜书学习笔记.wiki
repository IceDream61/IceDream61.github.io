= Contents =
    - [[#疑问|疑问]]
    - [[#绪论|绪论]]
        - [[#绪论#引言|引言]]
        - [[#绪论#基本术语|基本术语]]
        - [[#绪论#假设空间|假设空间]]
        - [[#绪论#归纳偏好|归纳偏好]]
        - [[#绪论#发展历程|发展历程]]
        - [[#绪论#应用现状|应用现状]]
        - [[#绪论#阅读材料|阅读材料]]
            - [[#绪论#阅读材料#学术会议、期刊|学术会议、期刊]]
            - [[#绪论#阅读材料#国内活动|国内活动]]
    - [[#模型评估与选择|模型评估与选择]]
        - [[#模型评估与选择#经验误差与过拟合|经验误差与过拟合]]
        - [[#模型评估与选择#评估方法|评估方法]]
            - [[#模型评估与选择#评估方法#留出法|留出法]]
            - [[#模型评估与选择#评估方法#交叉验证法|交叉验证法]]
            - [[#模型评估与选择#评估方法#自助法|自助法]]
            - [[#模型评估与选择#评估方法#调参与最终模型|调参与最终模型]]
        - [[#模型评估与选择#性能度量|性能度量]]
            - [[#模型评估与选择#性能度量#错误率与精度|错误率与精度]]
            - [[#模型评估与选择#性能度量#查准率、查全率与F1|查准率、查全率与F1]]
            - [[#模型评估与选择#性能度量#ROC 与 AUC|ROC 与 AUC]]
            - [[#模型评估与选择#性能度量#代价敏感错误率与代价曲线|代价敏感错误率与代价曲线]]
        - [[#模型评估与选择#比较检验|比较检验]]
            - [[#模型评估与选择#比较检验#假设检验|假设检验]]
            - [[#模型评估与选择#比较检验#交叉验证t检验|交叉验证t检验]]
            - [[#模型评估与选择#比较检验#McNemar检验|McNemar检验]]
            - [[#模型评估与选择#比较检验#Friedman检验 与 Nemenyi后续检验|Friedman检验 与 Nemenyi后续检验]]
        - [[#模型评估与选择#偏差与方差|偏差与方差]]
    - [[#线性模型|线性模型]]

    笔记按照目录记录于此，主要记录术语、理解和疑问。

= 疑问 =
1. 训练程度加深后的泛化错误率被方差主导，与训练数据自身的、非全局性的特性被学习器学到了所产生的过拟合，有什么区别？
2. TODO那些~

= 绪论 =
== 引言 ==
| 中文               | 英文                          |
|--------------------|-------------------------------|
| 机器学习           | machine learning              |
| 模型、学习器       | model, learner                |
| 学习算法           | learning algorithm            |
- 机器学习这门学科，致力于研究如何通过计算的手段，通过经验来改善系统自身的性能。
    - 主要内容是关于在计算机上从数据中产生“模型”的算法，即“学习算法”。
    - 有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时，模型会给我们提供相应的判断。
    - 如果说计算机科学是研究关于“算法”的学问，那么可以说机器学习是研究关于“学习算法”的学问。
== 基本术语 ==
| 中文               | 英文                                    | 备注                           |
|--------------------|-----------------------------------------|--------------------------------|
| 数据集             | data set                                |                                |
| 示例、样本         | instance, sample                        |                                |
| 属性、特征         | attribute, feature                      |                                |
| 属性值             | attribute value                         |                                |
| 属性空间、样本空间 | attribute space, sample space           |                                |
| 特征向量           | feature vector                          |                                |
| 维数               | demensionality                          |                                |
| 学习、训练         | learning, training                      |                                |
| 训练数据           | training data                           |                                |
| 训练样本           | training sample                         |                                |
| 训练集             | training set                            |                                |
| 假设               | hypothesis                              |                                |
| 潜在真实规律       | ground-truth                            |                                |
| 预测               | prediction                              |                                |
| 标记               | label                                   |                                |
| 样例               | example                                 | sample + label = example       |
| 标记空间           | label space                             |                                |
| 分类               | classification                          |                                |
| 回归               | regression                              |                                |
| 二分类             | binary classification                   | positive class, negative class |
| 多分类             | multi-class classification              |                                |
| 测试               | testing                                 |                                |
| 测试样本           | testing sample                          |                                |
| 聚类               | clustering                              | 簇, cluster                    |
| 监督学习           | supervised learning                     |                                |
| 无监督学习         | unsupervised learning                   |                                |
| 泛化               | generalization                          |                                |
| 分布               | distribution                            |                                |
| 独立同分布         | independent and identically distributed | i.i.d.                         |
== 假设空间 ==
| 中文     | 英文               | 备注                 |
|----------|--------------------|----------------------|
| 归纳     | induction          | 泛化, generalization |
| 演绎     | deduction          | 特化, specialization |
| 归纳学习 | inductive learning |                      |
| 概念     | concept            |                      |
| 匹配     | fit                |                      |
| 版本空间 | version space      |                      |
- 学习过程可以看做一个在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设
== 归纳偏好 ==
| 中文     | 英文           | 备注 |
|----------|----------------|------|
| 归纳偏好 | indective bias |      |
- 任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上等效的假设所迷惑，而无法产生确定的学习结果
    - 奥卡姆剃刀（Occam's razor）是一种常用的、自然科学研究中最基本的原则；但其并非唯一原则，其本身也存在不同的诠释
    - 多释原则（principle of multiple explanations）主张保留与经验观察一致的所有假设，这与集成学习（ensemble learning）方面的研究更加吻合
- 没有免费的午餐（NFL）定理最重要的寓意，是让我们清楚地认识到，脱离具体问题，空泛地谈论“什么学习算法更好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好
    - 学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用
== 发展历程 ==
== 应用现状 ==
== 阅读材料 ==
=== 学术会议、期刊 ===
- 机器学习领域
    - 最重要的国际学术会议
        - 国际机器学习会议（ICML）
        - 国际神经信息处理系统会议（NIPS）
        - 国际学习理论会议（COLT）
    - 重要的区域性会议
        - 欧洲机器学习会议（ECML）
        - 亚洲机器学习会议（ACML）
    - 最重要的国际学术期刊
        - Journal of Machine Learning Research
        - Machine Learning
- 人工智能领域
    - 重要会议
        - IJCAI
        - AAAI
    - 重要期刊
        - Artificial Intelligence
        - Journal of Artificial Intelligence Research
- 数据挖掘领域
    - 重要会议
        - KDD
        - ICDM
    - 重要期刊
        - ACM Transactions on Knowledge Discovery from Data
        - Data Mining and Knowledge Discovery
- 计算机视觉与模式识别
    - 重要会议
        - CVPR
    - 重要期刊
        - IEEE Transactions on Pattern Analysis and Machine Intelligence
- 神经网络领域
    - 重要期刊
        - Neural Computation
        - IEEE Transactions on Neural Networks and Learning Systems
- 统计学领域
    - 重要期刊
        - Annals of Statistics
=== 国内活动 ===
- 两年一次的中国机器学习大会（CCML）
- 每年举行的“机器学习及其应用”研讨会（MLA）

= 模型评估与选择 =
== 经验误差与过拟合 ==
| 中文               | 英文                            |
|--------------------|---------------------------------|
| 错误率、精度       | error rate, accuracy            |
| 误差               | error                           |
| 训练误差、经验误差 | training error, empirical error |
| 泛化误差           | generalization error            |
| 过拟合、欠拟合     | overfitting, underfitting       |
| 模型选择           | model selection                 |
|                    |                                 |
- 机器学习面临的问题通常是NP难甚至更难，而有效的学习算法必然是在多项式时间内运行完成
    - 若可彻底避免过拟合，则通过经验误差最小化就能获最优解，这就意味着我们构造性地证明了“P=NP”
    - 因此，只要相信“P≠NP”，过拟合就不可避免
== 评估方法 ==
| 中文     | 英文                   | 备注                    |
|----------|------------------------|-------------------------|
| 测试集   | testing set            |                         |
| 测试误差 | testing error          |                         |
| 留出法   | hold-out               |                         |
| 采样     | sampling               |                         |
| 分层采样 | stratified sampling    | 比如正反例比例相同      |
| 交叉验证 | cross validation       | k-fold cross validation |
| 留一法   | Leave-One-Out, LOO     |                         |
| 自助法   | bootstrapping          |                         |
| 自助采样 | bootstrapping sampling |                         |
| 包外估计 | out-of-bag estimate    |                         |
| 参数     | parameter              |                         |
| 调参     | parameter tuning       |                         |
| 验证集   | validation set         |                         |
=== 留出法 ===
- 直接把数据划分为两部分，一个是训练集、一个是测试集
    - 注意划分要尽可能保持数据分布的一致性
    - 一般还要配合若干次随机划分、重复进行试验评估后取平均值，更稳定可靠
    - 划分比例没有完美的解决方案，常见做法是将大约2/3到4/5的样本用于训练，剩余样本用作测试
=== 交叉验证法 ===
- 把数据划分为k个大小相似的子集，每个子集都尽可能保持数据分布的一致性
    - 每次用k-1个子集的并集当做训练集，余下的那个子集作为测试集；最终返回这k个测试结果的均值
    - 交叉验证法评估效果的稳定性和保真性，很大程度上取决于k的取值，因此常称为“k折交叉验证”
    - k最常用的取值是10，其他常用的有5、20等
- 若数据有m个样本，而令k=m，则是一种特例：留一法
    - 好处：不受随机样本划分方式的影响、评估模型和实际模型很相似，因此结果往往被认为比较准确
    - 缺陷：数据集比较大时，训练m个模型的计算开销可能是难以忍受的，这还未考虑算法调参；另外，其结果也未必永远比其他评估方法准确，“没有免费的午餐”定理对实验评估方法同样适用
=== 自助法 ===
- 从数据集D中随机采样m次得到D'，然后将D'作为训练集、D\D'作为测试集
    - 统计上看，D中约有36.8%的样本未出现在D'中
    - 好处：数据集较小、难以有效划分训练/测试集时很有用；能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处
    - 缺陷：改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些。
=== 调参与最终模型 ===
- 本质上和算法选择没什么区别：对每种参数配置都训练出模型，然后把对应最好模型的参数作为结果
    - 但请注意：学习算法的很多参数都是在实数范围内取值，而且很多强大的学习算法有大量参数需设定
        - 假设算法有3个参数，每个参数仅考虑5个候选值，这样对每一组训练/测试集就有5^3=125个模型需考察
        - 而有的大型“深度学习”模型甚至有上百亿个参数
    - 因此，必须在计算开销和性能估计之间进行折中，这非常困难，以至于在不少应用任务中，参数调得好不好往往对最终模型性能有关键性影响
- 在模型选择完成后，学习算法和参数配置已选定，此时应该用数据集D重新训练模型，得到最终模型
    - 由于实际使用中模型遇到的数据成为测试数据，因此为了区分，模型评估与选择中用于评估测试的数据集常成为“验证集”
    - 即：测试集上的判别效果可估计模型在实际使用时的泛化能力，而训练数据另外划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参
== 性能度量 ==
| 中文       | 英文                |
|------------|---------------------|
| 性能度量   | performance measure |
| 均方误差   | mean squared error  |
| 查准率     | precision           |
| 查全率     | recall              |
| 非均等代价 | unequal cost        |
- 回归任务最常用的性能度量是“均方误差”
=== 错误率与精度 ===
- 错误率：分类错误的样本数占样本总数的比例
- 精度：分类正确的样本数占样本总数的比例
=== 查准率、查全率与F1 ===
| 真实情况 | 预测结果     | >            |
| \/       | 正例         | 反例         |
|----------|--------------|--------------|
| 正例     | TP（真正例） | FN（假反例） |
| 反例     | FP（假正例） | TN（真反例） |
- 查准率 $P = \frac{TP}{TP+FP}$
- 查全率 $R = \frac{TP}{TP+FN}$
- 这是一对矛盾的度量，一般无法同时做到很高
    - 若希望将好瓜尽可能多地选出来，则可通过增加选瓜的数量来实现，将所有西瓜都选上，所有好瓜必然都被选上了，但这样查准率就会较低
    - 若希望选出的瓜中好瓜比例尽可能高，则可只挑选最有把握的瓜，但这样就难免会漏掉不少好瓜，使得查全率较低
    - 通常只有在一些简单任务中，才可能使查全率和查准率都很高
- 对两者的综合度量
    - 有较为简单的“平衡点”（Break-Event Point, BEP），即“查准率=查全率”时的取值
    - 还有最常用的 $F1 = \frac{2 \times TP}{样例总数 + TP - TN}$
    - 以及F1的一般形式 $F_\beta = \frac{(1+\beta^2) \times P \times R}{(\beta^2 \times P) + R}$
        - 其中 $\beta > 0$ 度量了查全率对查准率的相对重要性，$\beta > 1$时查全率有更大影响；$\beta < 1$时查准率有更大影响
    - 还有在n个矩阵上综合考察查准率和查全率的一些指标：
        - macro-P, macro-R, macro-F1
        - micro-P, micro-R, micro-F1
=== ROC 与 AUC ===
- 根据有多可能是正例来排序，再通过选择截断点来分类，是很常见的思路
- 这时，排序质量的好坏，体现了“一般情况下”泛化性能的好坏，ROC曲线就是从这个角度去看的
- ROC曲线绘制了“真正例率”和“假正例率”，而基于此借助计算曲线面积相比较，推算出AUC度量 
=== 代价敏感错误率与代价曲线 ===
- 很多时候，假正例和假反例所造成的后果不同，因此可为错误赋予“非均等代价”
- ROC曲线上的每一点对应了代价平面上的一条线段，取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价
== 比较检验 ==
- 在比较学习器性能的时候，由于其不确定性，我们需要借助统计手段
- 统计假设检验（hypothesis test）为我们提供了重要依据，由此我们可推断出，若在测试集上观察到学习器A比B好，则
    - A的泛化性能是否在统计意义上优于B
    - 这个结论的把握有多大
- 记“错误率”为$\epsilon$
=== 假设检验 ===
TODO 介绍了两种对关于单个学习器泛化性能的假设进行检验。
=== 交叉验证t检验 ===
TODO k-fold之后的算法比较策略
=== McNemar检验 ===
TODO 考虑学习器A和B的分类结果差别
=== Friedman检验 与 Nemenyi后续检验 ===
TODO 多个算法在同一数据集上的排序
== 偏差与方差 ==
- 偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的：
    - 偏差度量了学习算法的期望预测与真实预测的偏离程度，即刻画了学习算法本身的拟合能力；
    - 方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响；
    - 噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。
- 一般来说，偏差与方差是有冲突的，这称为偏差-方差窘境（bias-variance dilemma）：假定我们能控制学习算法的训练程度——
    - 训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化错误率；
    - 随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率；
    - 在训练程度充足后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身、非全局性的特征被学习器学到了，则将发生过拟合。
= 线性模型 =
